{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the final data pipeline is parsing each column of the CSV file into the correct data type and save the new data as Parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. `games_description.csv`\n",
    "\n",
    "The file wraps all columns as a string and have many columns with nested data types. Attempt to parse the data type from the start did not work. It's a challenge to process the column, which I actually welcomed 🤗.\n",
    "\n",
    "Schema:\n",
    "```\n",
    "name: string\n",
    "short_description: string\n",
    "long_description: string\n",
    "genres: object (array[string])\n",
    "minimum_system_requirement: object (struct[string])\n",
    "recommend_system_requirement: object (struct[string])\n",
    "release_date: date\n",
    "developer: object (array[string])\n",
    "publisher: object (array[string])\n",
    "overall_player_rating: categorical\n",
    "number_of_reviews_from_purchased_people: int32\n",
    "number_of_english_reviews: int32\n",
    "link: string\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"5716pt\" height=\"408pt\" viewBox=\"0.00 0.00 5716.00 408.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 404)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-404 5712,-404 5712,4 -4,4\"/>\n",
       "<!-- p1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3043,-400 2665,-400 2665,-362 3043,-362 3043,-400\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-384.8\" font-family=\"Times,serif\" font-size=\"14.00\">simple π 13/14</text>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-369.8\" font-family=\"Times,serif\" font-size=\"14.00\">[&quot;name&quot;, &quot;short_description&quot;, ... 11 other columns]</text>\n",
       "</g>\n",
       "<!-- p2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>p2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4491.5,-326 1216.5,-326 1216.5,-290 4491.5,-290 4491.5,-326\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-304.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [when(col(&quot;__POLARS_CSER_0x997c45506aff6681&quot;)).then(String(Not enough data)).otherwise(col(&quot;overall_player_rating&quot;)).strict_cast(Categorical(None, Lexical)).alias(&quot;overall_player_rating&quot;), when(col(&quot;__POLARS_CSER_0x997c45506aff6681&quot;)).then(col(&quot;overall_player_rating&quot;).str.extract([String((d+))]).strict_cast(Int32)).otherwise(col(&quot;number_of_reviews_from_purchased_people&quot;)).alias(&quot;number_of_reviews_from_purchased_people&quot;)]</text>\n",
       "</g>\n",
       "<!-- p1&#45;&#45;p2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p1--p2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2854,-361.72C2854,-350.7 2854,-336.78 2854,-326\"/>\n",
       "</g>\n",
       "<!-- p3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>p3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3311,-254 2397,-254 2397,-218 3311,-218 3311,-254\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-232.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [col(&quot;number_of_reviews_from_purchased_people&quot;).is_null().alias(&quot;__POLARS_CSER_0x997c45506aff6681&quot;)]</text>\n",
       "</g>\n",
       "<!-- p2&#45;&#45;p3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p2--p3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2854,-289.7C2854,-278.85 2854,-264.92 2854,-254.1\"/>\n",
       "</g>\n",
       "<!-- p4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>p4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5708,-182 0,-182 0,-146 5708,-146 5708,-182\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [col(&quot;genres&quot;).str.replace_many([Series, String()]).str.split([String(, )]), col(&quot;number_of_english_reviews&quot;).str.replace([String(,), String()]).strict_cast(Int32), col(&quot;minimum_system_requirement&quot;).str.replace_many([Series, String()]).str.split([String(, )]).map_list(), col(&quot;recommend_system_requirement&quot;).str.replace_many([Series, String()]).str.split([String(, )]).map_list(), col(&quot;developer&quot;).str.replace_many([Series, String()]).str.split([String(, )]), col(&quot;publisher&quot;).str.replace_many([Series, String()]).str.split([String(, )]), when(col(&quot;release_date&quot;).str.contains([String(d{1,2} w{3}, d{4})])).then(col(&quot;release_date&quot;).str.strptime([String(raise)])).otherwise(col(&quot;release_date&quot;).str.strptime([String(raise)])).alias(&quot;release_date&quot;), col(&quot;number_of_reviews_from_purchased_people&quot;).map_list()]</text>\n",
       "</g>\n",
       "<!-- p3&#45;&#45;p4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>p3--p4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2854,-217.7C2854,-206.85 2854,-192.92 2854,-182.1\"/>\n",
       "</g>\n",
       "<!-- p5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>p5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2940.5,-110 2767.5,-110 2767.5,-74 2940.5,-74 2940.5,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-88.3\" font-family=\"Times,serif\" font-size=\"14.00\">SLICE offset: 0; len: 5</text>\n",
       "</g>\n",
       "<!-- p4&#45;&#45;p5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>p4--p5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2854,-145.7C2854,-134.85 2854,-120.92 2854,-110.1\"/>\n",
       "</g>\n",
       "<!-- p6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>p6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3061.5,-38 2646.5,-38 2646.5,0 3061.5,0 3061.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Csv SCAN [../data_pipeline/data/games_description.csv]</text>\n",
       "<text text-anchor=\"middle\" x=\"2854\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">π */13;</text>\n",
       "</g>\n",
       "<!-- p5&#45;&#45;p6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>p5--p6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2854,-73.81C2854,-62.98 2854,-49.01 2854,-38.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "local_dir = Path(\"../data_pipeline/data\")\n",
    "\n",
    "\n",
    "def parse_reviews(value):\n",
    "    if \"%\" in value:\n",
    "        # Extract percentage and total number\n",
    "        match = re.search(r\"(\\d+)% of ([\\d,]+)\", value)\n",
    "        if match:\n",
    "            percentage = int(match.group(1))\n",
    "            total = int(match.group(2).replace(\",\", \"\"))\n",
    "            return int((percentage / 100) * total)\n",
    "    else:\n",
    "        # Extract the number directly\n",
    "        match = re.search(r\"\\(([\\d,]+)\\)\", value)\n",
    "        if match:\n",
    "            return int(match.group(1).replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "def parse_system_requirements(requirements_list):\n",
    "    result = {}\n",
    "    for item in requirements_list:\n",
    "        if \":\" in item:\n",
    "            key, value = item.split(\":\")[:2]\n",
    "            result[key.strip()] = value.strip()\n",
    "    return result\n",
    "\n",
    "\n",
    "df = pl.scan_csv(local_dir / \"games_description.csv\")\n",
    "df = df.with_columns(\n",
    "    pl.col(\"genres\").str.replace_many([\"]\", \"'\", \"[\"], \"\").str.split(\", \"),\n",
    "    pl.col(\"number_of_english_reviews\").str.replace_all(\",\", \"\").cast(pl.Int32),\n",
    "    pl.col([\"minimum_system_requirement\", \"recommend_system_requirement\"])\n",
    "    .str.replace_many([\"]\", \"'\", \"[\"], \"\")\n",
    "    .str.split(\", \")\n",
    "    .map_elements(parse_system_requirements, return_dtype=pl.Struct),\n",
    "    pl.col([\"developer\", \"publisher\"])\n",
    "    .str.replace_many([\"]\", \"'\", \"[\"], \"\")\n",
    "    .str.split(\", \"),\n",
    "    pl.when(pl.col(\"release_date\").str.contains(r\"\\d{1,2} \\w{3}, \\d{4}\"))\n",
    "    .then(pl.col(\"release_date\").str.to_date(\"%d %b, %Y\", strict=False))\n",
    "    .otherwise(pl.col(\"release_date\").str.to_date(\"%b %Y\", strict=False))\n",
    "    .alias(\"release_date\"),\n",
    "    pl.col(\"number_of_reviews_from_purchased_people\").map_elements(\n",
    "        parse_reviews, return_dtype=pl.Int32\n",
    "    ),\n",
    ")\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"number_of_reviews_from_purchased_people\").is_null())\n",
    "    .then(pl.lit(\"Not enough data\"))\n",
    "    .otherwise(pl.col(\"overall_player_rating\"))\n",
    "    .cast(pl.Categorical(\"lexical\"))\n",
    "    .alias(\"overall_player_rating\"),\n",
    "    pl.when(pl.col(\"number_of_reviews_from_purchased_people\").is_null())\n",
    "    .then(pl.col(\"overall_player_rating\").str.extract(r\"(\\d+)\").cast(pl.Int32))\n",
    "    .otherwise(pl.col(\"number_of_reviews_from_purchased_people\"))\n",
    "    .alias(\"number_of_reviews_from_purchased_people\"),\n",
    ")\n",
    "\n",
    "df.head().show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>overall_player_rating</th></tr><tr><td>cat</td></tr></thead><tbody><tr><td>&quot;Overwhelmingly Positive&quot;</td></tr><tr><td>&quot;Very Positive&quot;</td></tr><tr><td>&quot;Mixed&quot;</td></tr><tr><td>&quot;Mostly Positive&quot;</td></tr><tr><td>&quot;Mostly Negative&quot;</td></tr><tr><td>&quot;Very Negative&quot;</td></tr><tr><td>&quot;Not enough data&quot;</td></tr><tr><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 1)\n",
       "┌─────────────────────────┐\n",
       "│ overall_player_rating   │\n",
       "│ ---                     │\n",
       "│ cat                     │\n",
       "╞═════════════════════════╡\n",
       "│ Overwhelmingly Positive │\n",
       "│ Very Positive           │\n",
       "│ Mixed                   │\n",
       "│ Mostly Positive         │\n",
       "│ Mostly Negative         │\n",
       "│ Very Negative           │\n",
       "│ Not enough data         │\n",
       "│ Positive                │\n",
       "└─────────────────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"overall_player_rating\").unique().head(11).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. `games_ranking.csv`\n",
    "\n",
    "The file is significantly easier to parse.\n",
    "\n",
    "Schema:\n",
    "```\n",
    "game_name: string\n",
    "genre: categorical\n",
    "rank_type: categorical\n",
    "rank: uint8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>game_name</th><th>genre</th><th>rank_type</th><th>rank</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌───────────┬───────┬───────────┬──────┐\n",
       "│ game_name ┆ genre ┆ rank_type ┆ rank │\n",
       "│ ---       ┆ ---   ┆ ---       ┆ ---  │\n",
       "│ u32       ┆ u32   ┆ u32       ┆ u32  │\n",
       "╞═══════════╪═══════╪═══════════╪══════╡\n",
       "│ 0         ┆ 0     ┆ 0         ┆ 0    │\n",
       "└───────────┴───────┴───────────┴──────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "local_dir = Path(\"/teamspace/studios/this_studio/Steam-RecSys/data_pipeline/data\")\n",
    "schema = pl.Schema(\n",
    "    {\n",
    "        \"game_name\": pl.String(),\n",
    "        \"genre\": pl.Categorical(),\n",
    "        \"rank_type\": pl.Categorical(),\n",
    "        \"rank\": pl.UInt8(),\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pl.read_csv(local_dir / \"games_ranking.csv\", schema=schema)\n",
    "\n",
    "df.select(pl.all().is_null().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. `steam_game_reviews.csv`\n",
    "\n",
    "The file is the most important: our actual game review dataset. The most important thing is to parse the reviews into a suitable format for the recommendation system.\n",
    "\n",
    "Schema:\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing date: unconverted data remains: , 2015\n",
      "Error parsing date: unconverted data remains: , 2015\n",
      "Error parsing date: unconverted data remains: , 2016\n",
      "Error parsing date: time data '31 March, 2023' does not match format '%B %d'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread 'polars-0' panicked at crates/polars-python/src/map/series.rs:1089:26:\n",
      "called `Result::unwrap()` on an `Err` value: PyErr { type: <class 'ValueError'>, value: ValueError('31 March, 2023'), traceback: Some(<traceback object at 0x7fc4fa126180>) }\n",
      "--- PyO3 is resuming a panic after fetching a PanicException from Python. ---\n",
      "Python stack trace below:\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "called `Result::unwrap()` on an `Err` value: PyErr { type: <class 'ValueError'>, value: ValueError('31 March, 2023'), traceback: Some(<traceback object at 0x7fc4fa126180>) }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/polars/expr/expr.py:4276\u001b[0m, in \u001b[0;36mExpr._map_batches_wrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m-> 4276\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _check_for_numpy(result) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4278\u001b[0m         result \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mSeries(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_dtype)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/polars/expr/expr.py:4690\u001b[0m, in \u001b[0;36mExpr.map_elements.<locals>.wrap_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4688\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m   4689\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, PolarsInefficientMapWarning)\n\u001b[0;32m-> 4690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_elements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_nulls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_nulls\u001b[49m\n\u001b[1;32m   4692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/polars/series/series.py:5354\u001b[0m, in \u001b[0;36mSeries.map_elements\u001b[0;34m(self, function, return_dtype, skip_nulls)\u001b[0m\n\u001b[1;32m   5350\u001b[0m     pl_return_dtype \u001b[38;5;241m=\u001b[39m parse_into_dtype(return_dtype)\n\u001b[1;32m   5352\u001b[0m warn_on_inefficient_map(function, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname], map_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pyseries(\n\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_elements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_return_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_nulls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_nulls\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5357\u001b[0m )\n",
      "\u001b[0;31mPanicException\u001b[0m: called `Result::unwrap()` on an `Err` value: PyErr { type: <class 'ValueError'>, value: ValueError('31 March, 2023'), traceback: Some(<traceback object at 0x7fc4fa126180>) }"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "called `Result::unwrap()` on an `Err` value: PyErr { type: <class 'ValueError'>, value: ValueError('31 March, 2023'), traceback: Some(<traceback object at 0x7fc4fa126180>) }",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 39\u001b[0m\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mscan_csv(local_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteam_game_reviews.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, infer_schema_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     23\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m     24\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhours_played\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mFloat32),\n\u001b[1;32m     25\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelpful\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunny\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mInt64),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m.\u001b[39motherwise(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_null\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# df.filter(\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     pl.col(\"username\").str.contains_any(\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#         [\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# ).collect()\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/polars/lazyframe/frame.py:2050\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mPanicException\u001b[0m: called `Result::unwrap()` on an `Err` value: PyErr { type: <class 'ValueError'>, value: ValueError('31 March, 2023'), traceback: Some(<traceback object at 0x7fc4fa126180>) }"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "local_dir = Path(\"/teamspace/studios/this_studio/Steam-RecSys/data_pipeline/data\")\n",
    "\n",
    "\n",
    "def parse_date_without_year(date_str):\n",
    "    try:\n",
    "        # Try \"Day Month\" format\n",
    "        return datetime.strptime(date_str, \"%d %B\").replace(year=2024).date()\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try \"Month Day\" format\n",
    "            return datetime.strptime(date_str, \"%B %d\").replace(year=2024).date()\n",
    "        except ValueError as e:\n",
    "            print(f\"Error parsing date: {e}\")\n",
    "            raise ValueError(date_str)\n",
    "\n",
    "\n",
    "df = pl.scan_csv(local_dir / \"steam_game_reviews.csv\", infer_schema_length=10000)\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"hours_played\").str.replace_all(\",\", \"\").cast(pl.Float32),\n",
    "    pl.col([\"helpful\", \"funny\"]).str.replace_all(\",\", \"\").cast(pl.Int64),\n",
    "    pl.col(\"recommendation\").cast(pl.Categorical(\"lexical\")),\n",
    "    pl.when(pl.col(\"date\").str.contains(r\"\\w+ \\d{1,2}, \\d{4}\"))\n",
    "    .then(pl.col(\"date\").str.to_date(\"%B %d, %Y\", strict=False))\n",
    "    .when(pl.col(\"date\").str.contains(r\"\\d{1,2} \\w+, \\d{4}\"))\n",
    "    .then(pl.col(\"date\").str.to_date(\"%d %B, %Y\", strict=False))\n",
    "    .when(pl.col(\"date\").str.contains(r\"^(\\d{1,2} \\w+|\\w+ \\d{1,2})$\"))\n",
    "    .then(pl.col(\"date\").map_elements(parse_date_without_year, return_dtype=pl.Date))\n",
    "    .alias(\"date\"),\n",
    "    pl.when(pl.col(\"username\").str.contains(\"\\n\"))\n",
    "    .then(pl.col(\"username\").str.extract(r\"^(.*?)\\n\"))\n",
    "    .otherwise(pl.col(\"username\")),\n",
    ")\n",
    "\n",
    "df.select(pl.col(\"date\").is_null().sum()).collect()\n",
    "\n",
    "# df.filter(\n",
    "#     pl.col(\"username\").str.contains_any(\n",
    "#         [\n",
    "#             \"САКАКОК\",\n",
    "#             \"Ryuzaki Ken\",\n",
    "#             \"zakheron\",\n",
    "#             \"toxic40\",\n",
    "#             \"MiddayEnglishman\",\n",
    "#             \"StarOutOfSpace\",\n",
    "#             \"galacticdude7\",\n",
    "#         ]\n",
    "#     )\n",
    "# ).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
